{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c14335",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Example usage:\n",
    "model_params = config['modeling']['regression_model']['params']\n",
    "features = config['features']['regression']\n",
    "model_path = config['models']['regression_model']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65875f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Starting regression model development...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7ab33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Load processed data\n",
    "df = pd.read_csv('../data/processed/regression_data.csv')\n",
    "print(f\"Regression data loaded. Shape: {df.shape}\")\n",
    "\n",
    "# Load feature info\n",
    "import json\n",
    "with open('../data/processed/feature_info.json', 'r') as f:\n",
    "    feature_info = json.load(f)\n",
    "\n",
    "regression_features = feature_info['regression_features']\n",
    "print(f\"Number of features: {len(regression_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a813e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Prepare data for modeling\n",
    "print(\"=== PREPARING DATA FOR MODELING ===\")\n",
    "\n",
    "# Features and target\n",
    "X = df[regression_features]\n",
    "y = df['delay_duration']\n",
    "\n",
    "# Focus on delayed flights only (delay_duration > 0) for better regression performance\n",
    "delayed_mask = y > 0\n",
    "X_delayed = X[delayed_mask]\n",
    "y_delayed = y[delayed_mask]\n",
    "\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Delayed flights: {len(X_delayed):,}\")\n",
    "print(f\"Feature matrix shape: {X_delayed.shape}\")\n",
    "print(f\"Target statistics:\")\n",
    "print(f\"   - Mean delay: {y_delayed.mean():.2f} minutes\")\n",
    "print(f\"   - Median delay: {y_delayed.median():.2f} minutes\")\n",
    "print(f\"   - Max delay: {y_delayed.max():.2f} minutes\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_delayed, y_delayed, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522cfc8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Model training - Random Forest Regressor\n",
    "print(\"=== TRAINING RANDOM FOREST REGRESSOR ===\")\n",
    "\n",
    "# Initialize Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Regressor trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f76bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5: Model training - Linear Regression\n",
    "print(\"=== TRAINING LINEAR REGRESSION ===\")\n",
    "\n",
    "# Initialize Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742361e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6: Model evaluation\n",
    "print(\"=== MODEL EVALUATION ===\")\n",
    "\n",
    "# Function to evaluate regression model\n",
    "def evaluate_regression_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Additional metrics\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # Mean Absolute Percentage Error\n",
    "    \n",
    "    print(f\"MAE (Mean Absolute Error):     {mae:.2f} minutes\")\n",
    "    print(f\"RMSE (Root Mean Squared Error): {rmse:.2f} minutes\")\n",
    "    print(f\"R² Score:                      {r2:.4f}\")\n",
    "    print(f\"MAPE (Mean Absolute % Error):  {mape:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape\n",
    "    }\n",
    "\n",
    "# Evaluate both models\n",
    "rf_metrics = evaluate_regression_model(y_test, y_pred_rf, \"Random Forest Regressor\")\n",
    "lr_metrics = evaluate_regression_model(y_test, y_pred_lr, \"Linear Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3db53e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Visualization of results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Random Forest: Actual vs Predicted\n",
    "axes[0,0].scatter(y_test, y_pred_rf, alpha=0.5, color='blue')\n",
    "axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,0].set_xlabel('Actual Delay (minutes)')\n",
    "axes[0,0].set_ylabel('Predicted Delay (minutes)')\n",
    "axes[0,0].set_title(f'Random Forest: Actual vs Predicted\\n(R² = {rf_metrics[\"r2\"]:.3f})')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Linear Regression: Actual vs Predicted\n",
    "axes[0,1].scatter(y_test, y_pred_lr, alpha=0.5, color='green')\n",
    "axes[0,1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0,1].set_xlabel('Actual Delay (minutes)')\n",
    "axes[0,1].set_ylabel('Predicted Delay (minutes)')\n",
    "axes[0,1].set_title(f'Linear Regression: Actual vs Predicted\\n(R² = {lr_metrics[\"r2\"]:.3f})')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot - Random Forest\n",
    "residuals_rf = y_test - y_pred_rf\n",
    "axes[1,0].scatter(y_pred_rf, residuals_rf, alpha=0.5, color='blue')\n",
    "axes[1,0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1,0].set_xlabel('Predicted Delay (minutes)')\n",
    "axes[1,0].set_ylabel('Residuals')\n",
    "axes[1,0].set_title('Random Forest: Residuals Plot')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Feature Importance (Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': regression_features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[1,1].barh(range(len(feature_importance)), feature_importance['importance'])\n",
    "axes[1,1].set_yticks(range(len(feature_importance)))\n",
    "axes[1,1].set_yticklabels(feature_importance['feature'])\n",
    "axes[1,1].set_xlabel('Feature Importance')\n",
    "axes[1,1].set_title('Top 15 Feature Importances (Random Forest)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/model_results/regression_model_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7eea52",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: Error distribution analysis\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Error distribution - Random Forest\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(residuals_rf, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Random Forest: Error Distribution')\n",
    "plt.xlabel('Prediction Error (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Error distribution - Linear Regression\n",
    "residuals_lr = y_test - y_pred_lr\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(residuals_lr, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "plt.title('Linear Regression: Error Distribution')\n",
    "plt.xlabel('Prediction Error (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Model comparison\n",
    "plt.subplot(1, 3, 3)\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Random Forest': [rf_metrics['mae'], rf_metrics['rmse'], rf_metrics['r2']*100],\n",
    "    'Linear Regression': [lr_metrics['mae'], lr_metrics['rmse'], lr_metrics['r2']*100]\n",
    "}, index=['MAE', 'RMSE', 'R² (×100)'])\n",
    "\n",
    "metrics_comparison.plot(kind='bar', ax=plt.gca())\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/model_results/regression_error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a975968",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 9: SHAP Analysis for Regression\n",
    "print(\"=== SHAP ANALYSIS FOR REGRESSION ===\")\n",
    "\n",
    "# Create SHAP explainer for Random Forest (assuming it's the better model)\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "shap_values = explainer.shap_values(X_test.iloc[:1000])  # Use subset for speed\n",
    "\n",
    "# SHAP summary plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test.iloc[:1000], show=False)\n",
    "plt.title('SHAP Summary Plot - Regression Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/model_results/shap_summary_regression.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# SHAP feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test.iloc[:1000], plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance - Regression Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/model_results/shap_importance_regression.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f4331",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 10: OAI (Operational Adjustability Index) for Regression\n",
    "print(\"=== OPERATIONAL ADJUSTABILITY INDEX (OAI) FOR REGRESSION ===\")\n",
    "\n",
    "def calculate_oai_regression(X, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate OAI for regression model\n",
    "    OAI prioritizes controllable delays (carrier, late_aircraft)\n",
    "    \"\"\"\n",
    "    # Define controllable and uncontrollable features\n",
    "    controllable_features = ['carrier_delay', 'late_aircraft_delay', 'controllable_delay_minutes']\n",
    "    controllable_weight = 3.0\n",
    "    \n",
    "    uncontrollable_features = ['weather_delay', 'nas_delay', 'security_delay']\n",
    "    uncontrollable_weight = 1.0\n",
    "    \n",
    "    # Calculate weighted errors\n",
    "    oai_errors = []\n",
    "    \n",
    "    for idx in range(len(X)):\n",
    "        row = X.iloc[idx]\n",
    "        actual = y_true.iloc[idx]\n",
    "        predicted = y_pred[idx]\n",
    "        base_error = abs(actual - predicted)\n",
    "        \n",
    "        # Calculate controllable factor\n",
    "        controllable_factor = 0\n",
    "        for feature in controllable_features:\n",
    "            if feature in X.columns and row[feature] > 0:\n",
    "                controllable_factor += controllable_weight\n",
    "        \n",
    "        # Calculate uncontrollable factor  \n",
    "        uncontrollable_factor = 0\n",
    "        for feature in uncontrollable_features:\n",
    "            if feature in X.columns and row[feature] > 0:\n",
    "                uncontrollable_factor += uncontrollable_weight\n",
    "        \n",
    "        # Weight the error based on controllability\n",
    "        total_weight = controllable_factor + uncontrollable_factor\n",
    "        if total_weight > 0:\n",
    "            controllable_ratio = controllable_factor / total_weight\n",
    "            # Higher weight for controllable delays (we want to minimize these errors more)\n",
    "            weighted_error = base_error * (1 + controllable_ratio)\n",
    "        else:\n",
    "            weighted_error = base_error\n",
    "            \n",
    "        oai_errors.append(weighted_error)\n",
    "    \n",
    "    return np.array(oai_errors)\n",
    "\n",
    "# Calculate OAI metrics\n",
    "oai_errors_rf = calculate_oai_regression(X_test, y_test, y_pred_rf)\n",
    "standard_mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "oai_mae_rf = np.mean(oai_errors_rf)\n",
    "\n",
    "print(f\"Random Forest:\")\n",
    "print(f\"Standard MAE: {standard_mae_rf:.2f} minutes\")\n",
    "print(f\"OAI-weighted MAE: {oai_mae_rf:.2f} minutes\")\n",
    "print(f\"OAI emphasizes controllable delay errors\")\n",
    "\n",
    "# Calculate OAI for Linear Regression too\n",
    "oai_errors_lr = calculate_oai_regression(X_test, y_test, y_pred_lr)\n",
    "standard_mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "oai_mae_lr = np.mean(oai_errors_lr)\n",
    "\n",
    "print(f\"\\nLinear Regression:\")\n",
    "print(f\"Standard MAE: {standard_mae_lr:.2f} minutes\")\n",
    "print(f\"OAI-weighted MAE: {oai_mae_lr:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb2d70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 11: Model Selection and Saving\n",
    "print(\"=== MODEL SELECTION AND SAVING ===\")\n",
    "\n",
    "# Select best model based on R² score\n",
    "if rf_metrics['r2'] > lr_metrics['r2']:\n",
    "    best_model = rf_model\n",
    "    best_model_name = \"Random Forest Regressor\"\n",
    "    best_metrics = rf_metrics\n",
    "    best_predictions = y_pred_rf\n",
    "    best_oai_mae = oai_mae_rf\n",
    "else:\n",
    "    best_model = lr_model\n",
    "    best_model_name = \"Linear Regression\"\n",
    "    best_metrics = lr_metrics\n",
    "    best_predictions = y_pred_lr\n",
    "    best_oai_mae = oai_mae_lr\n",
    "\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Best R² Score: {best_metrics['r2']:.4f}\")\n",
    "print(f\"Best MAE: {best_metrics['mae']:.2f} minutes\")\n",
    "\n",
    "# Save the best model\n",
    "import os\n",
    "os.makedirs('../data/models/trained_models', exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, '../data/models/trained_models/regression_model.pkl')\n",
    "joblib.dump(explainer, '../data/models/trained_models/regression_explainer.pkl')\n",
    "\n",
    "# Save model performance metrics\n",
    "model_results = {\n",
    "    'model_type': 'regression',\n",
    "    'best_model': best_model_name,\n",
    "    'metrics': {\n",
    "        'random_forest': rf_metrics,\n",
    "        'linear_regression': lr_metrics\n",
    "    },\n",
    "    'oai_metrics': {\n",
    "        'random_forest_oai_mae': float(oai_mae_rf),\n",
    "        'linear_regression_oai_mae': float(oai_mae_lr),\n",
    "        'best_model_oai_mae': float(best_oai_mae)\n",
    "    },\n",
    "    'feature_count': len(regression_features),\n",
    "    'test_size': len(X_test),\n",
    "    'delayed_flights_only': True\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/models/trained_models/regression_results.json', 'w') as f:\n",
    "    json.dump(model_results, f, indent=2)\n",
    "\n",
    "print(\"Regression model saved successfully!\")\n",
    "print(f\"Model file: regression_model.pkl\")\n",
    "print(f\"Results file: regression_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce319cc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 12: Final Summary\n",
    "print(\"=== REGRESSION MODEL SUMMARY ===\")\n",
    "print(f\"✅ Model Type: Flight Delay Duration Prediction (Minutes)\")\n",
    "print(f\"✅ Best Model: {best_model_name}\")\n",
    "print(f\"✅ Dataset Size: {len(X_delayed):,} delayed flights\")\n",
    "print(f\"✅ Features Used: {len(regression_features)}\")\n",
    "print(f\"✅ Test Set Performance:\")\n",
    "print(f\"   - MAE:  {best_metrics['mae']:.2f} minutes\")\n",
    "print(f\"   - RMSE: {best_metrics['rmse']:.2f} minutes\")\n",
    "print(f\"   - R²:   {best_metrics['r2']:.4f}\")\n",
    "print(f\"   - MAPE: {best_metrics['mape']:.2f}%\")\n",
    "print(f\"✅ OAI Analysis: Completed (OAI MAE: {best_oai_mae:.2f} minutes)\")\n",
    "print(f\"✅ SHAP Analysis: Completed\")\n",
    "print(f\"✅ Model Saved: ../data/models/trained_models/regression_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
